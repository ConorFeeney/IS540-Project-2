{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Competition #2: Data Audit Report\n",
    "\n",
    "## Research Question & Goal:\n",
    "Is it possible to predict the sale price for each house in our data set? It is our job to predict the sales price for each house. For each Id in the test set, we must predict the value of the SalePrice variable. \n",
    "\n",
    "## Business Understanding:\n",
    "If you ask a home buyer to describe their dream house, they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But the dataset in this analysis proves that much more influences price negotiations than the number of bedrooms or whether there's a white-picket fence.\n",
    "\n",
    "A house is a building that functions as a home, ranging from simple dwellings such as rudimentary huts of nomadic tribes and the improvised shacks in shantytowns, to complex, fixed structures of wood, brick, concrete or other materials containing plumbing, ventilation and electrical systems. Houses use a range of different roofing systems to keep precipitation such as rain from getting into the dwelling space. Houses may have doors or locks to secure the dwelling space and protect its inhabitants and contents from burglars or other trespassers. Most conventional modern houses in Western cultures will contain one or more bedrooms and bathrooms, a kitchen or cooking area, and a living room. A house may have a separate dining room, or the eating area may be integrated into another room. Some large houses in North America also have a recreation room. \n",
    "\n",
    "With all the various ways a house can be constructed, and with all the different materials that can be used in its construction, how can one accurately determine the price of a house? Often when we refer to price we refer to sale price of a house. Architecture, foundations, floor space, and number of rooms all could play a part in determining the sale price of a house. The dataset that has been gathered for the purposes of this report contains 81 variables - 1 ID variable, 1 Target variable (SalePrice) and 79 Predictor variables, all listed below.    \n",
    "*     MSSubClass: The building class\n",
    "*     MSZoning: The general zoning classification\n",
    "*     LotFrontage: Linear feet of street connected to property\n",
    "*     LotArea: Lot size in square feet\n",
    "*     Street: Type of road access\n",
    "*     Alley: Type of alley access\n",
    "*     LotShape: General shape of property\n",
    "*     LandContour: Flatness of the property\n",
    "*     Utilities: Type of utilities available\n",
    "*     LotConfig: Lot configuration\n",
    "*     LandSlope: Slope of property\n",
    "*     Neighborhood: Physical locations within Ames city limits\n",
    "*     Condition1: Proximity to main road or railroad\n",
    "*     Condition2: Proximity to main road or railroad (if a second is present)\n",
    "*     BldgType: Type of dwelling\n",
    "*     HouseStyle: Style of dwelling\n",
    "*     OverallQual: Overall material and finish quality\n",
    "*     OverallCond: Overall condition rating\n",
    "*     YearBuilt: Original construction date\n",
    "*     YearRemodAdd: Remodel date\n",
    "*     RoofStyle: Type of roof\n",
    "*     RoofMatl: Roof material\n",
    "*     Exterior1st: Exterior covering on house\n",
    "*     Exterior2nd: Exterior covering on house (if more than one material)\n",
    "*     MasVnrType: Masonry veneer type\n",
    "*     MasVnrArea: Masonry veneer area in square feet\n",
    "*     ExterQual: Exterior material quality\n",
    "*     ExterCond: Present condition of the material on the exterior\n",
    "*     Foundation: Type of foundation\n",
    "*     BsmtQual: Height of the basement\n",
    "*     BsmtCond: General condition of the basement\n",
    "*     BsmtExposure: Walkout or garden level basement walls\n",
    "*     BsmtFinType1: Quality of basement finished area\n",
    "*     BsmtFinSF1: Type 1 finished square feet\n",
    "*     BsmtFinType2: Quality of second finished area (if present)\n",
    "*     BsmtFinSF2: Type 2 finished square feet\n",
    "*     BsmtUnfSF: Unfinished square feet of basement area\n",
    "*     TotalBsmtSF: Total square feet of basement area\n",
    "*     Heating: Type of heating\n",
    "*     HeatingQC: Heating quality and condition\n",
    "*     CentralAir: Central air conditioning\n",
    "*     Electrical: Electrical system\n",
    "*     1stFlrSF: First Floor square feet\n",
    "*     2ndFlrSF: Second floor square feet\n",
    "*     LowQualFinSF: Low quality finished square feet (all floors)\n",
    "*     GrLivArea: Above grade (ground) living area square feet\n",
    "*     BsmtFullBath: Basement full bathrooms\n",
    "*     BsmtHalfBath: Basement half bathrooms\n",
    "*     FullBath: Full bathrooms above grade\n",
    "*     HalfBath: Half baths above grade\n",
    "*     Bedroom: Number of bedrooms above basement level\n",
    "*     Kitchen: Number of kitchens\n",
    "*     KitchenQual: Kitchen quality\n",
    "*     TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "*     Functional: Home functionality rating\n",
    "*     Fireplaces: Number of fireplaces\n",
    "*     FireplaceQu: Fireplace quality\n",
    "*     GarageType: Garage location\n",
    "*     GarageYrBlt: Year garage was built\n",
    "*     GarageFinish: Interior finish of the garage\n",
    "*     GarageCars: Size of garage in car capacity\n",
    "*     GarageArea: Size of garage in square feet\n",
    "*     GarageQual: Garage quality\n",
    "*     GarageCond: Garage condition\n",
    "*     PavedDrive: Paved driveway\n",
    "*     WoodDeckSF: Wood deck area in square feet\n",
    "*     OpenPorchSF: Open porch area in square feet\n",
    "*     EnclosedPorch: Enclosed porch area in square feet\n",
    "*     3SsnPorch: Three season porch area in square feet\n",
    "*     ScreenPorch: Screen porch area in square feet\n",
    "*     PoolArea: Pool area in square feet\n",
    "*     PoolQC: Pool quality\n",
    "*     Fence: Fence quality\n",
    "*     MiscFeature: Miscellaneous feature not covered in other categories\n",
    "*     MiscVal: Value of miscellaneous feature\n",
    "*     MoSold: Month Sold\n",
    "*     YrSold: Year Sold\n",
    "*     SaleType: Type of sale\n",
    "*     SaleCondition: Condition of sale\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "## Training Set\n",
    "Our data set is divided into two parts, a training set and a testing set. To begin, we examine the training set. The data set contains 81 columns and 1460 rows. Our variables have the following breakdown: 36 are quantitative, 43 categorical and then Id and SalePrice are viewed separately. ID offers no predicitve value and SalePrice is our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing useful packages\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "import pylab \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# Read in Data file and define NaN values\n",
    "housetrain = pd.read_csv(\"train.csv\",header=0,na_values='None')\n",
    "housetrain.MSSubClass = housetrain.MSSubClass.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading in the data into our python workspace, we had to change one of our integer variables to be a string for ease as it was not an ordinal categorical variarble. We then printed out our data types to make sure we were happy with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print types\n",
    "pd.set_option('display.max_rows', 82)\n",
    "print(housetrain.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform a data describe to see the summary statistics of our data. As we can see below, some of our data has missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data describe\n",
    "pd.set_option('display.max_columns', 500)\n",
    "print(housetrain.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics are important to observe obvious outliers and initial trends.\n",
    "* Some of our variables contain missing data. This is by and large due to the formatting of the data in its use of \"NA\" to show when a house doesn't contain a feature. Nonetheless, it was decided to use it as missing initially to investigate if any variables contained imbalances due to missing data. Additionally, some variables contain all records (1460) but have zero as the minimum. Based on our analysis, this is more than likely due to the fact the house doesn't have this feature. For example, if we look at *TotBsmtSF*, which is the total square feet of the basement, we see that it is missing no records but has zero as a minimum. This more than likely means that the house does not have a basement.\n",
    "* We notice on average, there is more unfinished basement space than finished basement space. \n",
    "* There is on average 200 square feet less space upstairs than downstairs in houses. This makes sense as some homes don't have a complete second floor, and most houses are not built as a perfect square but reduce size on the second floor for structural requirements. \n",
    "* Some of our summary statistic variables are actually ordinal data so their summary statistics do not reveal much other than that they have no erroneous values (*OverallQual, OverallCond, YearBuilt, YearRemodAdd, MasVnrArea, GarageYrBlt, MoSold, YrSold*)\n",
    "\n",
    "Next, we look to quantify the missingness of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get numeric value to missing features\n",
    "for i in range(len(housetrain.columns)):\n",
    "    j = housetrain.columns[i]\n",
    "    miss=((1460-housetrain[str(j)].count())/1460)*100\n",
    "    print(\"The missingness of variable {}\".format(j))\n",
    "    print(\"{0:.2f}%\".format(miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = housetrain.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious example of missing is *PoolQC*. Looking at the graph it has the most number of missing values, as most houses in Ames do not have a pool on the property. Looking at the main culprits of missing values, we actaully see it makes sense that these variables have so many missing. *MiscFeature* is for features like tennis courts, second garages, elevators.Not many families can afford these types of add ons to their home, so the missingness of this variable makes sense. For the moment, it was decided to keep them in our dataset, as the few houses they do affect would see a dramatic increase in their sale price due to these features. Anything with around 50% of the data missing should be removed from further analysis, meaning we remove the following variables:\n",
    "* *PoolQC*\n",
    "* *MiscFeature*\n",
    "* *Alley*\n",
    "* *Fence*\n",
    "* *MasVnrType*\n",
    "* *FireplaceQu* \n",
    "\n",
    "However, despite the large number of missing values, these could be construed as rare noise so we will keep them for the moment. Later, we will use Principal Component Analysis and let PCA decide which variables should be kept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "As we saw, the biggest culprits of our missing data have perfectly logical reasons behind it. With that in mind, it was decided to fill in the NA values using either string representations of what was really going on (i.e. no pool) or zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alley : data description says NA means \"no alley access\"\n",
    "housetrain.loc[:, \"Alley\"] = housetrain.loc[:, \"Alley\"].fillna(\"None\")\n",
    "# BedroomAbvGr : NA most likely means 0\n",
    "housetrain.loc[:, \"BedroomAbvGr\"] = housetrain.loc[:, \"BedroomAbvGr\"].fillna(0)\n",
    "# BsmtQual etc : data description says NA for basement features is \"no basement\"\n",
    "housetrain.loc[:, \"BsmtQual\"] = housetrain.loc[:, \"BsmtQual\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"BsmtCond\"] = housetrain.loc[:, \"BsmtCond\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"BsmtExposure\"] = housetrain.loc[:, \"BsmtExposure\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"BsmtFinType1\"] = housetrain.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"BsmtFinType2\"] = housetrain.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"BsmtFullBath\"] = housetrain.loc[:, \"BsmtFullBath\"].fillna(0)\n",
    "housetrain.loc[:, \"BsmtHalfBath\"] = housetrain.loc[:, \"BsmtHalfBath\"].fillna(0)\n",
    "housetrain.loc[:, \"BsmtUnfSF\"] = housetrain.loc[:, \"BsmtUnfSF\"].fillna(0)\n",
    "# CentralAir : NA most likely means No\n",
    "housetrain.loc[:, \"CentralAir\"] = housetrain.loc[:, \"CentralAir\"].fillna(\"N\")\n",
    "# Condition : NA most likely means Normal\n",
    "housetrain.loc[:, \"Condition1\"] = housetrain.loc[:, \"Condition1\"].fillna(\"Norm\")\n",
    "housetrain.loc[:, \"Condition2\"] = housetrain.loc[:, \"Condition2\"].fillna(\"Norm\")\n",
    "# EnclosedPorch : NA most likely means no enclosed porch\n",
    "housetrain.loc[:, \"EnclosedPorch\"] = housetrain.loc[:, \"EnclosedPorch\"].fillna(0)\n",
    "# External stuff : NA most likely means average\n",
    "housetrain.loc[:, \"ExterCond\"] = housetrain.loc[:, \"ExterCond\"].fillna(\"TA\")\n",
    "housetrain.loc[:, \"ExterQual\"] = housetrain.loc[:, \"ExterQual\"].fillna(\"TA\")\n",
    "# Fence : data description says NA means \"no fence\"\n",
    "housetrain.loc[:, \"Fence\"] = housetrain.loc[:, \"Fence\"].fillna(\"No\")\n",
    "# FireplaceQu : data description says NA means \"no fireplace\"\n",
    "housetrain.loc[:, \"FireplaceQu\"] = housetrain.loc[:, \"FireplaceQu\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"Fireplaces\"] = housetrain.loc[:, \"Fireplaces\"].fillna(0)\n",
    "# Functional : data description says NA means typical\n",
    "housetrain.loc[:, \"Functional\"] = housetrain.loc[:, \"Functional\"].fillna(\"Typ\")\n",
    "# GarageType etc : data description says NA for garage features is \"no garage\"\n",
    "housetrain.loc[:, \"GarageType\"] = housetrain.loc[:, \"GarageType\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"GarageFinish\"] = housetrain.loc[:, \"GarageFinish\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"GarageQual\"] = housetrain.loc[:, \"GarageQual\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"GarageCond\"] = housetrain.loc[:, \"GarageCond\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"GarageArea\"] = housetrain.loc[:, \"GarageArea\"].fillna(0)\n",
    "housetrain.loc[:, \"GarageCars\"] = housetrain.loc[:, \"GarageCars\"].fillna(0)\n",
    "# HalfBath : NA most likely means no half baths above grade\n",
    "housetrain.loc[:, \"HalfBath\"] = housetrain.loc[:, \"HalfBath\"].fillna(0)\n",
    "# HeatingQC : NA most likely means typical\n",
    "housetrain.loc[:, \"HeatingQC\"] = housetrain.loc[:, \"HeatingQC\"].fillna(\"TA\")\n",
    "# KitchenAbvGr : NA most likely means 0\n",
    "housetrain.loc[:, \"KitchenAbvGr\"] = housetrain.loc[:, \"KitchenAbvGr\"].fillna(0)\n",
    "# KitchenQual : NA most likely means typical\n",
    "housetrain.loc[:, \"KitchenQual\"] = housetrain.loc[:, \"KitchenQual\"].fillna(\"TA\")\n",
    "# LotFrontage : NA most likely means no lot frontage\n",
    "housetrain.loc[:, \"LotFrontage\"] = housetrain.loc[:, \"LotFrontage\"].fillna(0)\n",
    "# LotShape : NA most likely means regular\n",
    "housetrain.loc[:, \"LotShape\"] = housetrain.loc[:, \"LotShape\"].fillna(\"Reg\")\n",
    "# MasVnrType : NA most likely means no veneer\n",
    "#housetrain.loc[:, \"MasVnrType\"] = housetrain.loc[:, \"MasVnrType\"].fillna(\"None\")\n",
    "housetrain.loc[:, \"MasVnrArea\"] = housetrain.loc[:, \"MasVnrArea\"].fillna(0)\n",
    "# MiscFeature : data description says NA means \"no misc feature\"\n",
    "housetrain.loc[:, \"MiscFeature\"] = housetrain.loc[:, \"MiscFeature\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"MiscVal\"] = housetrain.loc[:, \"MiscVal\"].fillna(0)\n",
    "# OpenPorchSF : NA most likely means no open porch\n",
    "housetrain.loc[:, \"OpenPorchSF\"] = housetrain.loc[:, \"OpenPorchSF\"].fillna(0)\n",
    "# PavedDrive : NA most likely means not paved\n",
    "housetrain.loc[:, \"PavedDrive\"] = housetrain.loc[:, \"PavedDrive\"].fillna(\"N\")\n",
    "# PoolQC : data description says NA means \"no pool\"\n",
    "housetrain.loc[:, \"PoolQC\"] = housetrain.loc[:, \"PoolQC\"].fillna(\"No\")\n",
    "housetrain.loc[:, \"PoolArea\"] = housetrain.loc[:, \"PoolArea\"].fillna(0)\n",
    "# SaleCondition : NA most likely means normal sale\n",
    "housetrain.loc[:, \"SaleCondition\"] = housetrain.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n",
    "# ScreenPorch : NA most likely means no screen porch\n",
    "housetrain.loc[:, \"ScreenPorch\"] = housetrain.loc[:, \"ScreenPorch\"].fillna(0)\n",
    "# TotRmsAbvGrd : NA most likely means 0\n",
    "housetrain.loc[:, \"TotRmsAbvGrd\"] = housetrain.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n",
    "# Utilities : NA most likely means all public utilities\n",
    "housetrain.loc[:, \"Utilities\"] = housetrain.loc[:, \"Utilities\"].fillna(\"AllPub\")\n",
    "# WoodDeckSF : NA most likely means no wood deck\n",
    "housetrain.loc[:, \"WoodDeckSF\"] = housetrain.loc[:, \"WoodDeckSF\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "Outliers are tricky when it comes to houses as bidding wars can drive up a price of a house, additionaly abstract features like tennis courts also greatly affect the selling price of a house, where the house is located can have serious implications as to the value of a house. Additionally with so many variables to maintain and manage, tracking down outliers is a difficult business. For simplicity, we will examine sale price against the above grade square feet as this variable tells us a very important feature of a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting scatter plot of the two variables\n",
    "plt.scatter(housetrain.GrLivArea, housetrain.SalePrice, c = \"blue\", marker = \"s\")\n",
    "plt.title(\"Looking for outliers\")\n",
    "plt.xlabel(\"GrLivArea\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have four outliers. Two houses that sold for far less than they should have based on the square footage, and two that sold for far more than the average. It was decided, based discussions and advice from the project brief on Kaggle to remove house that have a square footage of more than 4000 feet. This action removes 4 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housetrain = housetrain[housetrain.GrLivArea < 4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding\n",
    "Recoding involves substituting the values of a variable with values that are more useful. Recoding is done for a number of reasons; to create a more balanced variable by grouping small occurances, to reduce the number of distinct values, to group similar values together and so on. It is an important feature in data analysis as it helps to reduce the curse of dimensionaility later when we create dummy variables for our categorical variables.\n",
    "\n",
    "In this section, we will be conducting an initial recoding of our variables. This will be based on trying to keep a variable having no more than 5 distinct values. Groupings will be done using the methods listed above. The first task is to get the frequency counts of our current values in each variable as we will see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graphing missing data\n",
    "group = housetrain.columns.to_series().groupby(housetrain.dtypes).groups # grouping columns by type\n",
    "groups={k.name: v for k, v in group.items()} #  creating as dictionary\n",
    "\n",
    "# Taking only the object type col names\n",
    "objects=housetrain[groups['object'].values]\n",
    "#print(objects.head(5))\n",
    "# Printing freqiency counts\n",
    "for i in objects.columns:\n",
    "        #print('{} \\n' .format(objects[i]))\n",
    "        print(objects[i].value_counts())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, there are over a dozen varaibles that have more than 5 distinct values. There will be a lot of work involved in completing this recoding. Below find the list of variables, how we rocoded and why. If a variable is not listed, it was deemed that no changes were necessary to the variable.\n",
    "\n",
    "* MSSubClass: Complex - Requires Specilised case\n",
    "*     MSZoning: Complex - Requires Specilised case\n",
    "*     LotShape: Grouped the irregular options together to create more balanced variable\n",
    "*     LandContour: Changed to binary in order to create a more balanced variable\n",
    "*     LotConfig: Grouped Frontage together to create a more balanced variable\n",
    "*     Neighborhood: Complex - Requires Specilised case\n",
    "*     Condition1: Grouped railrowad and positive features to create a more balanced variable\n",
    "*     Condition2: Grouped railrowad and positive features to create a more balanced variable\n",
    "*     HouseStyle: Grouped 1 story and 1.5 story together, 2 story+ together to reduce number of distinct values\n",
    "*     OverallQual: Recoded to reduce number of distinct values/add numerical order\n",
    "*     OverallCond: Recoded to reduce number of distinct values/add numerical order\n",
    "*     RoofStyle: Regrouped everything not Gable or Hip to other to create more balanced variable\n",
    "*     RoofMatl: Made binary of standard vs not standard to reduce number of distinct values\n",
    "*     Exterior1st: Complex - Requires Specilised case\n",
    "*     Exterior2nd: Complex - Requires Specilised case\n",
    "*     ExterQual: Recoded to reduce number of distinct values/add numerical order\n",
    "*     ExterCond: Recoded to reduce number of distinct values/add numerical order\n",
    "*     Foundation: Grouped non standard to other to reduce number of distinct variables\n",
    "*     BsmtQual: Recoded to reduce number of distinct values/add numerical order\n",
    "*     BsmtCond: Recoded to reduce number of distinct values/add numerical order\n",
    "*     BsmtExposure: Recoded to reduce number of distinct values/add numerical orders\n",
    "*     BsmtFinType1: Grouped like values together to reduce number of distinct values\n",
    "*     BsmtFinType2: Grouped like values together to reduce number of distinct values\n",
    "*     Heating: Grouped Gas together to reduce number of distinct values\n",
    "*     HeatingQC: Recoded to reduce number of distinct values/add numerical order\n",
    "*     KitchenQual: Recoded to reduce number of distinct values/add numerical order\n",
    "*     Functional: Recoded to reduce number of distinct values/add numerical order\n",
    "*     GarageType: Complex - Requires Specilised case\n",
    "*     GarageQual: Recoded to reduce number of distinct values/add numerical order\n",
    "*     GarageCond: Recoded to reduce number of distinct values/add numerical order\n",
    "*     SaleType: Grouped similar contracts together to reduce number of distinct values\n",
    "*     SaleCondition: Complex - Requires Specilised case\n",
    "\n",
    "The next blocks of code execute the above descriptions. We replace all the \"Excellent\" and \"Good\" ratings with 3, \"Average\" with 2 and so on. We group frontage on either 2 sides and frontage on 3 sides to just frontage for *LotConfig* and many other changes in order to make the data more manageable, reduce the curse of dimensionaility, and ultimately, create a better model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reg or irreg\n",
    "housetrain['LotShape']=housetrain['LotShape'].replace(['IR1','IR2','IR3'],'IRReg')\n",
    "#print(housetrain['LotShape'].value_counts())\n",
    "\n",
    "# flat or not flat\n",
    "housetrain['LandContour']=housetrain['LandContour'].replace(['Bnk','HLS','Low'],'NotFlat')\n",
    "#print(housetrain['LandContour'].value_counts())\n",
    "\n",
    "# combined frontage\n",
    "housetrain['LotConfig']=housetrain['LotConfig'].replace(['FR2','FR3'],'Frontage')\n",
    "#print(housetrain['LotConfig'].value_counts())\n",
    "\n",
    "# combined rail and pos\n",
    "housetrain['Condition1']=housetrain['Condition1'].replace(['RRNn','RRAn','RRNe','RRAe'],'Rail')\n",
    "housetrain['Condition1']=housetrain['Condition1'].replace(['PosN','PosA'],'Pos')\n",
    "#print(housetrain['Condition1'].value_counts())\n",
    "\n",
    "# combined rail and pos\n",
    "housetrain['Condition2']=housetrain['Condition2'].replace(['RRNn','RRAn','RRNe','RRAe'],'Rail')\n",
    "housetrain['Condition2']=housetrain['Condition2'].replace(['PosN','PosA'],'Pos')\n",
    "#print(housetrain['Condition2'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['ExterQual']=housetrain['ExterQual'].replace(['Ex','Gd'],'Above Average')\n",
    "housetrain['ExterQual']=housetrain['ExterQual'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetrain['ExterQual'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['ExterCond']=housetrain['ExterCond'].replace(['Ex','Gd'],'Above Average')\n",
    "housetrain['ExterCond']=housetrain['ExterCond'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetrain['ExterCond'].value_counts())\n",
    "\n",
    "housetrain['HouseStyle']=housetrain['HouseStyle'].replace(['1Story','1.5Unf','1.5Fin'],'1to2Story')\n",
    "housetrain['HouseStyle']=housetrain['HouseStyle'].replace(['2Story','2.5Unf','2.5Fin'],'2+Story')\n",
    "#print(housetrain['HouseStyle'].value_counts())\n",
    "\n",
    "housetrain['RoofStyle']=housetrain['RoofStyle'].replace(['Flat','Gambrel','Mansard','Shed'],'Other')\n",
    "#print(housetrain['RoofStyle'].value_counts())\n",
    "\n",
    "housetrain['RoofMatl']=housetrain['RoofMatl'].replace(['ClyTile','Membran','Metal','Roll','Tar&Grv','WdShake','WdShngl'],'Other')\n",
    "#print(housetrain['RoofMatl'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['SaleType']=housetrain['SaleType'].replace(['WD','CWD','VWD'],'Warrenty Deed')\n",
    "housetrain['SaleType']=housetrain['SaleType'].replace(['Con','ConLw','ConLI','ConLD'],'Contract')\n",
    "#print(housetrain['SaleType'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['GarageCond']=housetrain['GarageCond'].replace(['Ex','Gd'],'Above Average')\n",
    "housetrain['GarageCond']=housetrain['GarageCond'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetrain['GarageCond'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['GarageQual']=housetrain['GarageQual'].replace(['Ex','Gd'],'Above Average')\n",
    "housetrain['GarageQual']=housetrain['GarageQual'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetrain['GarageQual'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['Functional']=housetrain['Functional'].replace(['Min1','Min2'],'Min')\n",
    "housetrain['Functional']=housetrain['Functional'].replace(['Maj1','Maj2','Sev','Sal'],'Maj')\n",
    "#print(housetrain['Functional'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['KitchenQual']=housetrain['KitchenQual'].replace(['Ex','Gd'],'Above Average')\n",
    "housetrain['KitchenQual']=housetrain['KitchenQual'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetrain['KitchenQual'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['HeatingQC']=housetrain['HeatingQC'].replace(['Ex','Gd'],'Above Average')\n",
    "housetrain['HeatingQC']=housetrain['HeatingQC'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetrain['HeatingQC'].value_counts())\n",
    "\n",
    "# Merging Gas\n",
    "housetrain['Heating']=housetrain['Heating'].replace(['GasA','GasW'],'Gas')\n",
    "#print(housetrain['Heating'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['BsmtFinType2']=housetrain['BsmtFinType2'].replace(['ALQ','Rec'],'Average')\n",
    "housetrain['BsmtFinType2']=housetrain['BsmtFinType2'].replace(['BLQ','LwQ'],'Below Average')\n",
    "#print(housetrain['BsmtFinType2'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['BsmtFinType1']=housetrain['BsmtFinType1'].replace(['ALQ','Rec'],'Average')\n",
    "housetrain['BsmtFinType1']=housetrain['BsmtFinType1'].replace(['BLQ','LwQ'],'Below Average')\n",
    "#print(housetrain['BsmtFinType1'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['BsmtCond']=housetrain['BsmtCond'].replace(['Ex','Gd'],'Above Average')\n",
    "housetrain['BsmtCond']=housetrain['BsmtCond'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetrain['BsmtCond'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetrain['BsmtQual']=housetrain['BsmtQual'].replace(['Ex','Gd'],'Above Average')\n",
    "housetrain['BsmtQual']=housetrain['BsmtQual'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetrain['BsmtQual'].value_counts())\n",
    "\n",
    "# Foundation: One of the more standard options or other\n",
    "housetrain['Foundation']=housetrain['Foundation'].replace(['BrkTil','Slab','Stone','Wood'],'Other')\n",
    "#print(housetrain['Foundation'].value_counts())\n",
    "group = housetrain.columns.to_series().groupby(housetrain.dtypes).groups # grouping columns by type\n",
    "groups={k.name: v for k, v in group.items()} #  creating as dictionary\n",
    "\n",
    "# Taking only the object type col names\n",
    "objects=housetrain[groups['object'].values]\n",
    "for i in objects.columns:\n",
    "        #print('{} \\n' .format(objects[i]))\n",
    "        print(objects[i].value_counts())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode some categorical features as ordered numbers when there is information in the order\n",
    "housetrain = housetrain.replace({\"BsmtCond\" : {\"No\" : 0, \"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                        \"Fence\":{\"GdPrv\":2,\"GdWo\":2,\"MnPrv\":1,\"MnWw\":1,\"No\":0},\n",
    "                        \"LotShape\":{\"IRReg\":0,\"Reg\":1},\n",
    "                        \"CentralAir\":{\"N\":0,\"Y\":1},\n",
    "                        \"LandContour\":{\"NotFlat\":0,\"Lvl\":1},\n",
    "                        \"PavedDrive\":{\"N\":0,\"Y\":1,\"P\":1},\n",
    "                       \"BsmtQual\" : {\"No\" : 0, \"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"ExterCond\" : {\"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"ExterQual\" : {\"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"BsmtFinType1\":{\"No\":0,\"Unf\":1,\"Below Average\":1,\"Average\":2,\"GLQ\":3},\n",
    "                        \"BsmtFinType2\":{\"No\":0,\"Unf\":1,\"Below Average\":1,\"Average\":2,\"GLQ\":3},\n",
    "                       \"Functional\" : {\"Maj\" : 1, \"Mod\" : 2, \"Min\" : 3, \"Typ\" : 4},\n",
    "                       \"GarageCond\" : {\"No\" : 0, \"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"GarageQual\" : {\"No\" : 0, \"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"HeatingQC\" : {\"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"KitchenQual\" : {\"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3}}\n",
    "                     )\n",
    "\n",
    "# Create new features\n",
    "# 1* Simplifications of existing features\n",
    "housetrain[\"OverallQual\"] = housetrain.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                                                       4 : 2, 5 : 2, 6 : 2, # average\n",
    "                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                                                      })\n",
    "housetrain[\"OverallCond\"] = housetrain.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                                                       4 : 2, 5 : 2, 6 : 2, # average\n",
    "                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                                                      })\n",
    "\n",
    "\n",
    "\n",
    "group = housetrain.columns.to_series().groupby(housetrain.dtypes).groups # grouping columns by type\n",
    "groups={k.name: v for k, v in group.items()} #  creating as dictionary\n",
    "\n",
    "# Taking only the object type col names\n",
    "objects=housetrain[groups['object'].values]\n",
    "for i in objects.columns:\n",
    "        #print('{} \\n' .format(objects[i]))\n",
    "        print(objects[i].value_counts())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int64=housetrain[groups['int64'].values]\n",
    "for i in int64.columns:\n",
    "        #print('{} \\n' .format(objects[i]))\n",
    "        print(int64[i].value_counts())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining variables\n",
    "housetrain['BsmtFinSF']=housetrain['BsmtFinSF1']+housetrain['BsmtFinSF2']\n",
    "housetrain['PorchSF']=housetrain['OpenPorchSF']+housetrain['EnclosedPorch']+housetrain['3SsnPorch']+housetrain['ScreenPorch']\n",
    "\n",
    "housetrain['hasPool'] = np.where(housetrain['PoolArea']>0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising\n",
    "Most statistical methods (the parametric methods) include the assumption that the sample is drawn from a population where the values have a Normal distribution. One of the first steps of statistical analysis of your data is therefore to check the distribution of the different variables.\n",
    "\n",
    "Upon completing the task of dealing with missing values and errors in the data, it was decided to move on to normalizing our data.\n",
    "\n",
    "The Normal distribution is symmetrical, not very peaked or very flat-topped, and if we examine the charts below, we can see that our data is often skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Printing plots for int 64 and float64\n",
    "# #quantvar = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "#             'LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd',\n",
    "#             'Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea'\n",
    "#            ,'MiscVal','SalePrice']\n",
    "quantvar = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "            'LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','PorchSF','PoolArea'\n",
    "           ,'MiscVal','SalePrice']\n",
    "cont_plot=housetrain[quantvar]\n",
    "for i in range(len(cont_plot.columns)):\n",
    "        plt.hist(cont_plot.iloc[:,i].dropna(),bins=30)\n",
    "        plt.title('%s' % cont_plot.columns[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Examining the charts, we note several points of interest. We have several variables that skewed to the right. There do not appear to be any left skewed. This is more than likely caused by the presence of smaller outliers that were missed by our earlier scatter plot. \n",
    "\n",
    "For dealing with skew, the following transformations perform well:\n",
    "\n",
    "* The log transformation (sometimes computed log(x+A) where A is some constant. This is done to deal with negative or 0 values.\n",
    "* The Square Root function\n",
    "* Converting to a Fraction, i.e. 1/x\n",
    "* The Powers transformation\n",
    "\n",
    "We can also use some combination thereof. For our base model, it was decided to keep things simple. As we try to improve our models, we will try alternate methods.\n",
    "\n",
    "For right skewed data, the log transformation works well, and this was the selected transformation for our model for the severly right skewed data listed above. It is suspected that if the outliers were dealt with, the data would become more normally distributed. This was the decided approach with a view of returning to this as we seek to improve the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_transform(feature):\n",
    "    housetrain[feature] = np.log1p(housetrain[feature].values) # does a log transform on x+1\n",
    "\n",
    "#log transforming variables\n",
    "log_transform('GrLivArea')\n",
    "log_transform('PorchSF')\n",
    "log_transform('1stFlrSF')\n",
    "log_transform('2ndFlrSF')\n",
    "log_transform('BsmtUnfSF')\n",
    "log_transform('BsmtFinSF')\n",
    "log_transform('TotalBsmtSF')\n",
    "log_transform('LotArea')\n",
    "log_transform('LotFrontage')\n",
    "log_transform('KitchenAbvGr')\n",
    "log_transform('GarageArea')\n",
    "log_transform('MasVnrArea')\n",
    "log_transform('WoodDeckSF')\n",
    "log_transform('PorchSF')\n",
    "log_transform('SalePrice')\n",
    "quantvar = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "            'LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','PorchSF','PoolArea'\n",
    "           ,'MiscVal','SalePrice']\n",
    "cont_plot=housetrain[quantvar]\n",
    "for i in range(len(cont_plot.columns)):\n",
    "        plt.hist(cont_plot.iloc[:,i].dropna(),bins=30)\n",
    "        plt.title('%s' % cont_plot.columns[i])\n",
    "        plt.show()\n",
    "# f = pd.melt(housetrain, value_vars=quantitative)\n",
    "# g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False)\n",
    "# g = g.map(sns.distplot, \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, by using a log transformation we have normalised our data (excluding the zero values representing missing) and have tidied up the outliers.\n",
    "\n",
    "# Standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "def standard(data,method):\n",
    "    \"\"\"Standarising data using various methods.\n",
    "    \n",
    "    Method 1 is MinMax scaling \n",
    "    Method 2 is decimal\n",
    "    Method 3 is Z score\n",
    "    Version Control:\n",
    "    Initial coding\n",
    "    ------------------------------------------\n",
    "    Date 4-Feb-18, Author: Conor Feeney, Desc: Initial Coding\n",
    "    \"\"\"\n",
    "    if method == 1:\n",
    "        X_std = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))\n",
    "        data = X_std * (1 - 0) + 0\n",
    "        return data\n",
    "    elif method==2:\n",
    "        data = (data)/(10**len(str(int(max(data)))))\n",
    "        return data\n",
    "    elif method ==3:\n",
    "        data = (data - data.mean(axis=0))/data.std(axis=0)\n",
    "        data=st.norm.cdf(data)\n",
    "        return data\n",
    "    elif method==4:\n",
    "        return data\n",
    "    \n",
    "for i in range(len(housetrain.columns)):     \n",
    "    if housetrain.iloc[:,i].dtype !=object:   \n",
    "        housetrain.iloc[:,i]=standard(housetrain.iloc[:,i],3)\n",
    "housetrain.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "Next, we needed to select the predictor variables with low pair-wise correlation values. In order to do this, we used Spearman's correlation test to determine the statistical dependence between the rankings of pairs of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spearman Test\n",
    "\n",
    "The Spearman's rank-order correlation is the nonparametric version of the Pearson product-moment correlation. Spearman's correlation coefficient, measures the strength and direction of association between two ranked variables. This test has some assumptions. You need two variables that are either ordinal, interval or ratio. Although you would normally hope to use a Pearson product-moment correlation on interval or ratio data, the Spearman correlation can be used when the assumptions of the Pearson correlation are markedly violated. However, Spearman's correlation determines the strength and direction of the monotonic relationship between your two variables rather than the strength and direction of the linear relationship between your two variables, which is what Pearson's correlation determines. A monotonic relationship is a relationship that does one of the following: (1) as the value of one variable increases, so does the value of the other variable; or (2) as the value of one variable increases, the other variable value decreases.\n",
    "\n",
    "Below, you can observe the results of our Spearman correlation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr=['LotFrontage','LotArea','LotShape',\"BsmtFinType1\",\"BsmtFinType2\",'LandSlope','ExterQual','ExterCond','OverallQual','OverallCond','YearBuilt','YearRemodAdd','MasVnrArea','BsmtQual','BsmtCond','BsmtExposure','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','HeatingQC','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','KitchenQual','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea','GarageQual','GarageCond','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','MoSold','YrSold','SalePrice']\n",
    "\n",
    "housetrain[corr].corr(method='spearman').style.format(\"{:.2}\").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above results, we see some expected correlations:\n",
    "* **SalePrice** is positively correlated with YearBuilt, OverallQual, BsmtQual,TotalBsmtSF, GrLivArea, FullBath, KitchenQual, GarageCars, GarageArea\n",
    "* **BsmtFinType1** and **BsmtFinType2** are positively correlated with BsmtFinSF1 and BsmtFinSF2 respectively\n",
    "* **ExterQual** is positively correlated with OverallQual, YearBuilt, YearRemodAdd, BsmtQual, KitchenQual, GarageYrBlt and SalePrice \n",
    "* **OverallQual** is positively correlated with YearBuilt, ExterQual and KitchenQual\n",
    "* **YearBlt** is positively correlated with GarageCars, GarageYrBlt, BsmntQual, YearRemodAdd, SalePrice\n",
    "* **YearRemodAdd** is positively correlated with YearBuilt, KitchenQual, GarageYrBlt, SalePrice\n",
    "* **BsmtQual** is positively correlated with YearBuilt, GarageYrBlt\n",
    "* **GarageYrBlt** variable is positively correlated with YearBuilt, YearRemodAdd, and BsmtQual, and GarageCars\n",
    "* **1stFlrSF** variable is positively correlated with TotalBsmtSF\n",
    "* **TotRmsAbvGrd** variable is positively correlated with GrLivArea and BedroomAbvGrd\n",
    "* **GarageArea** variable is positively correlated with GarageCars\n",
    "* **GarageCond** variable is positively correlated with GarageQual\n",
    "* **BsmtFinSF1** is positively correlated with BsmtFullBath\n",
    "* **TotalBsmtSF** is positively correlated with 1stFlrSF, SalePrice\n",
    "* **2ndFlrSF** is positively correlated with GrLivArea, and HalfBath\n",
    "* **BsmtFullBath** is positively correlated with BsmtFinSF1\n",
    "* **FullBath** is positively correlated with GrLivArea and SalePrice\n",
    "* **BedroomAbvGr** is positively correlated with TotalRmsAbvGrd\n",
    "* **KitchenQual** is positively correlated with YearRemodAdd, OverallQual, and SalePrice\n",
    "* **GarageCars** is positively correlated with YrBuilt, GarageYrBlt, GarageArea, and Sale Price\n",
    "* **GarageArea** is positively correlated with Sale Price, Garage Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA\n",
    "\n",
    "Next, for Categorical vs Continuous variables, we used the analysis of variance (ANOVA). ANOVA provides a statistical test of whether or not the means of several groups are equal.\n",
    "\n",
    "To keep our ANOVA correlations simple, we chose to only analyze our target variable, SalesPrice, against each categorical variable. Below, you can observe the results of our ANOVA correlation tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.Condition1.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.Condition1 == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Norm'], d_data['Feedr'], d_data['Artery'], d_data['Rail'], d_data['Pos'])\n",
    "    print('Condition1 v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.Condition2.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.Condition2 == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Norm'], d_data['Feedr'], d_data['Artery'], d_data['Rail'], d_data['Pos'])\n",
    "    print('Condition2 v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.Foundation.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.Foundation == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['PConc'], d_data['CBlock'], d_data['Other'])\n",
    "    print('Foundation v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.Heating.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.Heating == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Gas'],d_data['Grav'],d_data['Wall'],d_data['OthW'],d_data['Floor'])\n",
    "    print('Heating v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.HouseStyle.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.HouseStyle == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['1to2Story'],d_data['2+Story'],d_data['SLvl'],d_data['SFoyer'])\n",
    "    print('HouseStyle v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.LotConfig.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.LotConfig == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Inside'],d_data['Corner'],d_data['CulDSac'],d_data['Frontage'])\n",
    "    print('LotConfig v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.RoofMatl.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.RoofMatl == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['CompShg'],d_data['Other'])\n",
    "    print('RoofMatl v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.RoofStyle.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.RoofStyle == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Gable'],d_data['Hip'],d_data['Other'])\n",
    "    print('RoofStyle v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.SaleType.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.SaleType == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Warrenty Deed'],d_data['New'],d_data['COD'],d_data['Contract'],d_data['Oth'])\n",
    "    print('SaleType v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.MSZoning.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.MSZoning == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['RL'],d_data['RM'],d_data['FV'],d_data['RH'],d_data['C (all)'])\n",
    "    print('MSZoning v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.Street.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.Street == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Pave'],d_data['Grvl'])\n",
    "    print('Street v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.Alley.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.Alley == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['None'],d_data['Grvl'],d_data['Pave'])\n",
    "    print('Alley v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.Utilities.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.Utilities == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['NoSeWa'],d_data['AllPub'])\n",
    "    print('Utilities v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.Electrical.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.Electrical == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['SBrkr'],d_data['FuseA'],d_data['FuseF'],d_data['FuseP'],d_data['Mix'])\n",
    "    print('Electrical v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.BldgType.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.BldgType == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['1Fam'],d_data['TwnhsE'],d_data['Duplex'],d_data['Twnhs'],d_data['2fmCon'])\n",
    "    print('BldgType v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.MasVnrType.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.MasVnrType == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['BrkFace'],d_data['Stone'],d_data['BrkCmn'])\n",
    "    print('MasVnrType v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.FireplaceQu.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.FireplaceQu == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Gd'],d_data['TA'],d_data['Fa'],d_data['Ex'],d_data['Po'])\n",
    "    print('FireplaceQu v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.GarageType.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.GarageType == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Attchd'],d_data['Detchd'],d_data['BuiltIn'],d_data['No'],d_data['Basment'],d_data['CarPort'],d_data['2Types'])\n",
    "    print('GarageType v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.GarageFinish.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.GarageFinish == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Unf'],d_data['RFn'],d_data['Fin'],d_data['No'])\n",
    "    print('GarageFinish v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.PoolQC.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.PoolQC == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Fa'],d_data['Gd'],d_data['Ex'])\n",
    "    print('PoolQC v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.MiscFeature.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.MiscFeature == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Shed'],d_data['Gar2'],d_data['Othr'],d_data['TenC'])\n",
    "    print('MiscFeature v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.SaleCondition.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.SaleCondition == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Normal'],d_data['Partial'],d_data['Abnorml'],d_data['Family'],d_data['Alloca'],d_data['AdjLand'])\n",
    "    print('SaleCondition v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Should there only be one group??\n",
    "for i in (['SalePrice']):\n",
    "    grps = pd.unique(housetrain.SaleCondition.values)\n",
    "    d_data = {grp:housetrain[i][housetrain.SaleCondition == grp] for grp in grps}\n",
    "        #run anova\n",
    "    anova = stats.f_oneway(d_data['Normal'],d_data['Partial'],d_data['Abnorml'],d_data['Family'],d_data['Alloca'],d_data['AdjLand'])\n",
    "    print('SaleCondition v Variable {} Result {}'.format(i,anova))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our ANOVA analysis resulted in the following correlations:\n",
    "* **SalePrice** is positively correlated with Utilities and PoolQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "Multiple linear regression attempts to model the relationship between two or more explanatory variables and a response variable by fitting a linear equation to observed data. Every value of the independent variable x is associated with a value of the dependent variable y. In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Such models are called linear models.Most commonly, the conditional mean of y given the value of X is assumed to be an affine function of X, where X is our predictor variables. Like all forms of regression analysis, linear regression focuses on the conditional probability distribution of y given X, rather than on the joint probability distribution of y and X, which is the domain of multivariate analysis.\n",
    "\n",
    "Linear regression was the first type of regression analysis to be studied rigorously and to be used extensively in practical applications. This is because models which depend linearly on their unknown parameters are easier to fit than models which are non-linearly related to their parameters and because the statistical properties of the resulting estimators are easier to determine. Linear regression models are often fitted using the least squares approach, but they may also be fitted in other ways, such as by minimizing the \"lack of fit\" in some other norm (as with least absolute deviations regression), or by minimizing a penalized version of the least squares cost function as in ridge regression (L2-norm penalty) and lasso (L1-norm penalty). We will be looking at some of these alternate versions in further advanced models.\n",
    "\n",
    "## Assumptions\n",
    "* Weak exogeneity\n",
    "* Constant variance\n",
    "* Linearity\n",
    "* Lack of perfect multicollinearity\n",
    "* Independence of errors\n",
    "\n",
    "Below, we begin to build our model. An important thing to note is that dimensionaility can cause serious problems with MLR, meaning we will also need to incorporate some feature selection techniques in order to reduce the number of predictor variables. This should help reduce the possibility of overfitting, as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing packages for linear regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# creating a copy of the data set\n",
    "testtrain=pd.DataFrame.copy(housetrain)\n",
    "testtrain=testtrain.drop('Utilities',axis=1)\n",
    "testtrain=testtrain.drop('PoolQC',axis=1)\n",
    "testtrain=testtrain.drop('PoolArea',axis=1)\n",
    "# creating dummy variables for categorical variables\n",
    "group = testtrain.columns.to_series().groupby(testtrain.dtypes).groups # grouping columns by type\n",
    "groups={k.name: v for k, v in group.items()} #  creating as dictionary\n",
    "\n",
    "dummies = pd.get_dummies(testtrain[groups['object'].values])\n",
    "testrain = testtrain.join(dummies)\n",
    "\n",
    "# dropping ID so its not included in the analysis\n",
    "testrain=testrain.drop('Id',axis=1)\n",
    "\n",
    "# Pulling our target variable into its own dataframe\n",
    "y=pd.DataFrame.copy(testrain['SalePrice'])\n",
    "\n",
    "# Dropping variables that had been recoded\n",
    "testrain=testrain.drop('SalePrice',axis=1)\n",
    "testrain=testrain.drop(testrain[groups['object'].values],axis=1)\n",
    "testrain=testrain.drop('GarageYrBlt',axis=1)\n",
    "testrain=testrain.drop('OpenPorchSF',axis=1)\n",
    "testrain=testrain.drop('EnclosedPorch',axis=1)\n",
    "testrain=testrain.drop('3SsnPorch',axis=1)\n",
    "testrain=testrain.drop('ScreenPorch',axis=1)\n",
    "testrain=testrain.drop('BsmtFinSF1',axis=1)\n",
    "testrain=testrain.drop('BsmtFinSF2',axis=1)\n",
    "\n",
    "#Variables not present in testing set so wont explain any variance\n",
    "\n",
    "testrain=testrain.drop('Condition2_Rail',axis=1)\n",
    "testrain=testrain.drop('Exterior1st_ImStucc',axis=1)\n",
    "testrain=testrain.drop('Exterior1st_Stone',axis=1)\n",
    "testrain=testrain.drop('Exterior2nd_Other',axis=1)\n",
    "testrain=testrain.drop('Heating_Floor',axis=1)\n",
    "testrain=testrain.drop('Heating_OthW',axis=1)\n",
    "testrain=testrain.drop('Electrical_Mix',axis=1)\n",
    "testrain=testrain.drop('MiscFeature_TenC',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that we have removed additional columns from our data set. These dummy variables were removed because they do not exist in the test data set, so they will provide no explained variance in the test set, hence we drop them so they will not be included in the model. The variables in question are highlighted in the code above using comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imporing packages\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# creating linear regression object  \n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "X=pd.DataFrame.copy(testrain)\n",
    "# splitting the data into testing and training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)   \n",
    "# Train the model using the training sets\n",
    "\n",
    "# fitting our model to the data\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model shows over 90% accuracy, but overfitting will clearly be an issue due to the 200+ variables used. When dealing with dimensionailty issues, it is important to incorporate feature selection. There are several options for feature selection. In this next section we will examine Recursive Feature Selection. Recursive feature elimination is based on the idea to repeatedly construct a model (for example a regression model) and choose either the best or worst performing feature (for example based on coefficients), setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. Features are then ranked according to when they were eliminated. As such, it is a greedy optimization for finding the best performing subset of features.\n",
    "\n",
    "The stability of RFE depends heavily on the type of model that is used for feature ranking at each iteration. Some benefits of feature selection are:\n",
    "* Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n",
    "* Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "* Reduces Training Time: Less data means that algorithms train faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "# load data\n",
    "\n",
    "# arbitrarily decide to keep 85 variables\n",
    "rfe = RFE(regr, 85)\n",
    "rfe.fit(testrain, y)\n",
    "#print(\"Num Features: %d\") % fit.n_features_\n",
    "# print(\"Selected Features: {}\".format(fit.n_features_))\n",
    "# print(\"Selected Features: {}\".format(fit.support_))\n",
    "# print(\"Selected Features: {}\".format(fit.ranking_))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(testrain, y, test_size=0.3)   \n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = rfe.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.5f\"\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.5f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We now have a RMSE  of 0.15, and an R squared value of around 70%. The R squared value tells us the amount of variance our model explains. Using feature selection has substantianally reduced the error while simultaneously increasing the varaince our model explains. As this is our base model, the number of variables to keep was arbitrarily choosen. Later we will use a loop to try and find a more optimal solution.\n",
    "\n",
    "An important thing to note here is that the model failed to include any continious variables in the model. In our opinion, this is a failing of the model that will need to be addressed, because variables like square footage and overall quality definitely impact the selling price of a house. In order to prove this, we decided to build a model using only numeric and ordinal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantvar = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "            'LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','PorchSF'\n",
    "           ,'MiscVal']\n",
    "intvar = ['BsmtCond','BsmtExposure','Fence','LotShape','CentralAir','LandContour','PavedDrive','BsmtQual','ExterCond',\n",
    "          'ExterQual','BsmtFinType1','BsmtFinType2','Functional','GarageCond','GarageQual','HeatingQC','KitchenQual','LandSlope'\n",
    "         ,'OverallQual','OverallCond']\n",
    "\n",
    "rfe = RFE(regr, 25)\n",
    "rfe.fit(testrain[quantvar+intvar], y)\n",
    "#print(\"Num Features: %d\") % fit.n_features_\n",
    "# print(\"Selected Features: {}\".format(fit.n_features_))\n",
    "# print(\"Selected Features: {}\".format(fit.support_))\n",
    "# print(\"Selected Features: {}\".format(fit.ranking_))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(testrain[quantvar+intvar], y, test_size=0.4, random_state=0)   \n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = rfe.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.5f\"\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.5f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we actually get better results than when we select 25 out of the 35 numeric variables. This shows us that we will need both categorical and continuous variables in our model as individually they are both strong so together they should augment each other. We have a RMSE of 0.09, and an R squared value of nearly 90%. This is better than the feature selection linear regression model we saw earlier.\n",
    "\n",
    "It was decided to take a new approach in our model building. In order to improve our results we built a Lasso Regression model. Lasso stands for least absolute shrinkage and selection operator. This method performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces. Regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting. The goal of this learning problem is to find a function that fits or predicts the outcome that minimizes the expected error over all possible inputs. Lasso was originally formulated for least squares models and this simple case reveals a substantial amount about the behavior of the estimator, including its relationship to ridge regression and best subset selection and the connections between lasso coefficient estimates and so-called soft thresholding. It also reveals that (like standard linear regression) the coefficient estimates need not be unique if covariates are collinear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=pd.DataFrame.copy(testrain)\n",
    "\n",
    "# creating list of choices for alpha\n",
    "clf = linear_model.LassoCV(alphas=[0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, \n",
    "                          0.3, 0.6, 1]) \n",
    "# splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)  \n",
    "\n",
    "# fitting data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Highlighting the best alpha\n",
    "alpha = clf.alpha_\n",
    "print(\"Best alpha :\", alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alpha here refers to the constant that multiplies the L1 term. The L1 term is used in the regularisation, meaning it will influence the model significantly if not calculated correctly. Therefore having an appropriate alpha is important. Fortunately, in python the lasso regression package will pick the most optimol one from a provided list, as seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predicting\n",
    "\n",
    "y_test_las = clf.predict(X_test)\n",
    "coefs = pd.Series(clf.coef_, index = X_train.columns)\n",
    "print(\"clf picked \" + str(sum(coefs != 0)) + \" features and eliminated the other \" +  \\\n",
    "      str(sum(coefs == 0)) + \" features\")\n",
    "imp_coefs = pd.concat([coefs.sort_values().head(10),\n",
    "                     coefs.sort_values().tail(10)])\n",
    "imp_coefs.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the clf Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see how many features were selected for our model. The graph then shows us the top ten postive coefficients and bottom ten negative coefficients. The first thing we noticed is that the lasso model picks a both numeric and categorical data. Below we see the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "var=r2_score(y_test, y_test_las)\n",
    "\n",
    "rmse=np.sqrt(mean_squared_error(y_test, y_test_las))\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "modelCV = LassoCV()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "\n",
    "\n",
    "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "print('Var {}, RMSE {}'.format(var,rmse))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our best model so far. We have over 90% of our variance explained and also have the lowest RMSE which is around 0.08. Additionally, we used a k-fold cross validation in order to test for overfitting. We are looking for extreme value differences in the results. As we can see, all the values in our array are reasonably close together showing no obvious signs of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Set\n",
    "## Data Understanding\n",
    "We have looked at and preprocessed the data for the training set (above). Next we look at the test data set. The first thing we do is read in the data and get some summary statistics.\n",
    "\n",
    "The test set contains 80 variables and 1459 rows of data. The missing varaible is the target variable SalePrice. All other variables are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in our test data set\n",
    "housetest = pd.read_csv(\"test.csv\",header=0,na_values='None')\n",
    "housetest.MSSubClass = housetest.MSSubClass.astype(str)\n",
    "# Data describe\n",
    "\n",
    "print(housetest.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some of our variables contain missing data. This is by and large due to the formatting of the data in its use of \"NA\" to show when a house doesn't contain a feature. Nonetheless it was decided to use it as missing initially to investigate if any variables contained a imbalances due to missing data. Additionally, some variables contain all records (1460) but have zero as the minimum. Based on our analysis, this is more than likely due to the fact the house doesn't have this feature. For example, if we look at TotBsmtSF, which is the total square feet of the basement, we see that it is missing no records but has zero as a minimum. This more than likely means that the house does not have a basement.\n",
    "* We notice on average, there is more unfinished basement space than finished basement space. This is similar to the training set\n",
    "* There is on average substantionally less square feet space upstairs than downstairs in houses. This makes sense as some homes don't have a complete second floor, and most houses are not built as a perfect square but reduce size on the second floor for structural requirements. However the size of this difference could be explained if there was more one and one and a half story homes in the testing set.\n",
    "* Some of our summary statistic variables are actually ordinal data so their summary statistics do not reveal much other than that they have no erroneous values (OverallQual, OverallCond, YearBuilt, YearRemodAdd, MasVnrArea, GarageYrBlt, MoSold, YrSold)\n",
    "\n",
    "In this next section we will examine the missingness of our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get numeric value to missing features\n",
    "for i in range(len(housetest.columns)):\n",
    "    j = housetest.columns[i]\n",
    "    miss=((1459-housetest[str(j)].count())/1459)*100\n",
    "    print(\"The missingness of variable {}\".format(j))\n",
    "    print(\"{0:.2f}%\".format(miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = housetest.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we notice is that we have a more variables with missing data in our test set than our training set. It is important to note, however, that all the variables with significant amounts of missing data are the same, and nearly to the exact same level, as our training set.\n",
    "\n",
    "## Imputation\n",
    "Just like our training set, we impute our missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alley : data description says NA means \"no alley access\"\n",
    "housetest.loc[:, \"Alley\"] = housetest.loc[:, \"Alley\"].fillna(\"None\")\n",
    "# BedroomAbvGr : NA most likely means 0\n",
    "housetest.loc[:, \"BedroomAbvGr\"] = housetest.loc[:, \"BedroomAbvGr\"].fillna(0)\n",
    "# BsmtQual etc : data description says NA for basement features is \"no basement\"\n",
    "housetest.loc[:, \"BsmtQual\"] = housetest.loc[:, \"BsmtQual\"].fillna(\"No\")\n",
    "housetest.loc[:, \"BsmtCond\"] = housetest.loc[:, \"BsmtCond\"].fillna(\"No\")\n",
    "housetest.loc[:, \"BsmtExposure\"] = housetest.loc[:, \"BsmtExposure\"].fillna(\"No\")\n",
    "housetest.loc[:, \"BsmtFinType1\"] = housetest.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n",
    "housetest.loc[:, \"BsmtFinType2\"] = housetest.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n",
    "housetest.loc[:, \"BsmtFullBath\"] = housetest.loc[:, \"BsmtFullBath\"].fillna(0)\n",
    "housetest.loc[:, \"BsmtHalfBath\"] = housetest.loc[:, \"BsmtHalfBath\"].fillna(0)\n",
    "housetest.loc[:, \"BsmtUnfSF\"] = housetest.loc[:, \"BsmtUnfSF\"].fillna(0)\n",
    "# CentralAir : NA most likely means No\n",
    "housetest.loc[:, \"CentralAir\"] = housetest.loc[:, \"CentralAir\"].fillna(\"N\")\n",
    "# Condition : NA most likely means Normal\n",
    "housetest.loc[:, \"Condition1\"] = housetest.loc[:, \"Condition1\"].fillna(\"Norm\")\n",
    "housetest.loc[:, \"Condition2\"] = housetest.loc[:, \"Condition2\"].fillna(\"Norm\")\n",
    "# EnclosedPorch : NA most likely means no enclosed porch\n",
    "housetest.loc[:, \"EnclosedPorch\"] = housetest.loc[:, \"EnclosedPorch\"].fillna(0)\n",
    "# External stuff : NA most likely means average\n",
    "housetest.loc[:, \"ExterCond\"] = housetest.loc[:, \"ExterCond\"].fillna(\"TA\")\n",
    "housetest.loc[:, \"ExterQual\"] = housetest.loc[:, \"ExterQual\"].fillna(\"TA\")\n",
    "# Fence : data description says NA means \"no fence\"\n",
    "housetest.loc[:, \"Fence\"] = housetest.loc[:, \"Fence\"].fillna(\"No\")\n",
    "# FireplaceQu : data description says NA means \"no fireplace\"\n",
    "housetest.loc[:, \"FireplaceQu\"] = housetest.loc[:, \"FireplaceQu\"].fillna(\"No\")\n",
    "housetest.loc[:, \"Fireplaces\"] = housetest.loc[:, \"Fireplaces\"].fillna(0)\n",
    "# Functional : data description says NA means typical\n",
    "housetest.loc[:, \"Functional\"] = housetest.loc[:, \"Functional\"].fillna(\"Typ\")\n",
    "# GarageType etc : data description says NA for garage features is \"no garage\"\n",
    "housetest.loc[:, \"GarageType\"] = housetest.loc[:, \"GarageType\"].fillna(\"No\")\n",
    "housetest.loc[:, \"GarageFinish\"] = housetest.loc[:, \"GarageFinish\"].fillna(\"No\")\n",
    "housetest.loc[:, \"GarageQual\"] = housetest.loc[:, \"GarageQual\"].fillna(\"No\")\n",
    "housetest.loc[:, \"GarageCond\"] = housetest.loc[:, \"GarageCond\"].fillna(\"No\")\n",
    "housetest.loc[:, \"GarageArea\"] = housetest.loc[:, \"GarageArea\"].fillna(0)\n",
    "housetest.loc[:, \"GarageCars\"] = housetest.loc[:, \"GarageCars\"].fillna(0)\n",
    "# HalfBath : NA most likely means no half baths above grade\n",
    "housetest.loc[:, \"HalfBath\"] = housetest.loc[:, \"HalfBath\"].fillna(0)\n",
    "# HeatingQC : NA most likely means typical\n",
    "housetest.loc[:, \"HeatingQC\"] = housetest.loc[:, \"HeatingQC\"].fillna(\"TA\")\n",
    "# KitchenAbvGr : NA most likely means 0\n",
    "housetest.loc[:, \"KitchenAbvGr\"] = housetest.loc[:, \"KitchenAbvGr\"].fillna(0)\n",
    "# KitchenQual : NA most likely means typical\n",
    "housetest.loc[:, \"KitchenQual\"] = housetest.loc[:, \"KitchenQual\"].fillna(\"TA\")\n",
    "# LotFrontage : NA most likely means no lot frontage\n",
    "housetest.loc[:, \"LotFrontage\"] = housetest.loc[:, \"LotFrontage\"].fillna(0)\n",
    "# LotShape : NA most likely means regular\n",
    "housetest.loc[:, \"LotShape\"] = housetest.loc[:, \"LotShape\"].fillna(\"Reg\")\n",
    "# MasVnrType : NA most likely means no veneer\n",
    "#housetest.loc[:, \"MasVnrType\"] = housetest.loc[:, \"MasVnrType\"].fillna(\"None\")\n",
    "housetest.loc[:, \"MasVnrArea\"] = housetest.loc[:, \"MasVnrArea\"].fillna(0)\n",
    "# MiscFeature : data description says NA means \"no misc feature\"\n",
    "housetest.loc[:, \"MiscFeature\"] = housetest.loc[:, \"MiscFeature\"].fillna(\"No\")\n",
    "housetest.loc[:, \"MiscVal\"] = housetest.loc[:, \"MiscVal\"].fillna(0)\n",
    "# OpenPorchSF : NA most likely means no open porch\n",
    "housetest.loc[:, \"OpenPorchSF\"] = housetest.loc[:, \"OpenPorchSF\"].fillna(0)\n",
    "# PavedDrive : NA most likely means not paved\n",
    "housetest.loc[:, \"PavedDrive\"] = housetest.loc[:, \"PavedDrive\"].fillna(\"N\")\n",
    "# PoolQC : data description says NA means \"no pool\"\n",
    "housetest.loc[:, \"PoolQC\"] = housetest.loc[:, \"PoolQC\"].fillna(\"No\")\n",
    "housetest.loc[:, \"PoolArea\"] = housetest.loc[:, \"PoolArea\"].fillna(0)\n",
    "# SaleCondition : NA most likely means normal sale\n",
    "housetest.loc[:, \"SaleCondition\"] = housetest.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n",
    "# ScreenPorch : NA most likely means no screen porch\n",
    "housetest.loc[:, \"ScreenPorch\"] = housetest.loc[:, \"ScreenPorch\"].fillna(0)\n",
    "# TotRmsAbvGrd : NA most likely means 0\n",
    "housetest.loc[:, \"TotRmsAbvGrd\"] = housetest.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n",
    "# Utilities : NA most likely means all public utilities\n",
    "housetest.loc[:, \"Utilities\"] = housetest.loc[:, \"Utilities\"].fillna(\"AllPub\")\n",
    "# WoodDeckSF : NA most likely means no wood deck\n",
    "housetest.loc[:, \"WoodDeckSF\"] = housetest.loc[:, \"WoodDeckSF\"].fillna(0)\n",
    "# Bsmt Square foot: missing probably means no basement\n",
    "housetest.loc[:, \"BsmtFinSF1\"] = housetest.loc[:, \"BsmtFinSF1\"].fillna(0)\n",
    "housetest.loc[:, \"BsmtFinSF2\"] = housetest.loc[:, \"BsmtFinSF2\"].fillna(0)\n",
    "housetest.loc[:, \"TotalBsmtSF\"] = housetest.loc[:, \"TotalBsmtSF\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding\n",
    "We also need to carry out recoding on our test set. We need to ensure that the test set dose not contain any extra values not seen in the training or is missing any values not seen in the training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graphing missing data\n",
    "group = housetest.columns.to_series().groupby(housetest.dtypes).groups # grouping columns by type\n",
    "groups={k.name: v for k, v in group.items()} #  creating as dictionary\n",
    "\n",
    "# Taking only the object type col names\n",
    "objects=housetest[groups['object'].values]\n",
    "#print(objects.head(5))\n",
    "# Printing freqiency counts\n",
    "for i in objects.columns:\n",
    "        #print('{} \\n' .format(objects[i]))\n",
    "        print(objects[i].value_counts())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reg or irreg\n",
    "housetest['LotShape']=housetest['LotShape'].replace(['IR1','IR2','IR3'],'IRReg')\n",
    "#print(housetest['LotShape'].value_counts())\n",
    "\n",
    "# flat or not flat\n",
    "housetest['LandContour']=housetest['LandContour'].replace(['Bnk','HLS','Low'],'NotFlat')\n",
    "#print(housetest['LandContour'].value_counts())\n",
    "\n",
    "# combined frontage\n",
    "housetest['LotConfig']=housetest['LotConfig'].replace(['FR2','FR3'],'Frontage')\n",
    "#print(housetest['LotConfig'].value_counts())\n",
    "\n",
    "# combined rail and pos\n",
    "housetest['Condition1']=housetest['Condition1'].replace(['RRNn','RRAn','RRNe','RRAe'],'Rail')\n",
    "housetest['Condition1']=housetest['Condition1'].replace(['PosN','PosA'],'Pos')\n",
    "#print(housetest['Condition1'].value_counts())\n",
    "\n",
    "# combined rail and pos\n",
    "housetest['Condition2']=housetest['Condition2'].replace(['RRNn','RRAn','RRNe','RRAe'],'Rail')\n",
    "housetest['Condition2']=housetest['Condition2'].replace(['PosN','PosA'],'Pos')\n",
    "#print(housetest['Condition2'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['ExterQual']=housetest['ExterQual'].replace(['Ex','Gd'],'Above Average')\n",
    "housetest['ExterQual']=housetest['ExterQual'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetest['ExterQual'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['ExterCond']=housetest['ExterCond'].replace(['Ex','Gd'],'Above Average')\n",
    "housetest['ExterCond']=housetest['ExterCond'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetest['ExterCond'].value_counts())\n",
    "\n",
    "housetest['HouseStyle']=housetest['HouseStyle'].replace(['1Story','1.5Unf','1.5Fin'],'1to2Story')\n",
    "housetest['HouseStyle']=housetest['HouseStyle'].replace(['2Story','2.5Unf','2.5Fin'],'2+Story')\n",
    "#print(housetest['HouseStyle'].value_counts())\n",
    "\n",
    "housetest['RoofStyle']=housetest['RoofStyle'].replace(['Flat','Gambrel','Mansard','Shed'],'Other')\n",
    "#print(housetest['RoofStyle'].value_counts())\n",
    "\n",
    "housetest['RoofMatl']=housetest['RoofMatl'].replace(['ClyTile','Membran','Metal','Roll','Tar&Grv','WdShake','WdShngl'],'Other')\n",
    "#print(housetest['RoofMatl'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['SaleType']=housetest['SaleType'].replace(['WD','CWD','VWD'],'Warrenty Deed')\n",
    "housetest['SaleType']=housetest['SaleType'].replace(['Con','ConLw','ConLI','ConLD'],'Contract')\n",
    "#print(housetest['SaleType'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['GarageCond']=housetest['GarageCond'].replace(['Ex','Gd'],'Above Average')\n",
    "housetest['GarageCond']=housetest['GarageCond'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetest['GarageCond'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['GarageQual']=housetest['GarageQual'].replace(['Ex','Gd'],'Above Average')\n",
    "housetest['GarageQual']=housetest['GarageQual'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetest['GarageQual'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['Functional']=housetest['Functional'].replace(['Min1','Min2'],'Min')\n",
    "housetest['Functional']=housetest['Functional'].replace(['Maj1','Maj2','Sev','Sal'],'Maj')\n",
    "#print(housetest['Functional'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['KitchenQual']=housetest['KitchenQual'].replace(['Ex','Gd'],'Above Average')\n",
    "housetest['KitchenQual']=housetest['KitchenQual'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetest['KitchenQual'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['HeatingQC']=housetest['HeatingQC'].replace(['Ex','Gd'],'Above Average')\n",
    "housetest['HeatingQC']=housetest['HeatingQC'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetest['HeatingQC'].value_counts())\n",
    "\n",
    "# Merging Gas\n",
    "housetest['Heating']=housetest['Heating'].replace(['GasA','GasW'],'Gas')\n",
    "#print(housetest['Heating'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['BsmtFinType2']=housetest['BsmtFinType2'].replace(['ALQ','Rec'],'Average')\n",
    "housetest['BsmtFinType2']=housetest['BsmtFinType2'].replace(['BLQ','LwQ'],'Below Average')\n",
    "#print(housetest['BsmtFinType2'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['BsmtFinType1']=housetest['BsmtFinType1'].replace(['ALQ','Rec'],'Average')\n",
    "housetest['BsmtFinType1']=housetest['BsmtFinType1'].replace(['BLQ','LwQ'],'Below Average')\n",
    "#print(housetest['BsmtFinType1'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['BsmtCond']=housetest['BsmtCond'].replace(['Ex','Gd'],'Above Average')\n",
    "housetest['BsmtCond']=housetest['BsmtCond'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetest['BsmtCond'].value_counts())\n",
    "\n",
    "# Recoding to have less options and grouping similar\n",
    "housetest['BsmtQual']=housetest['BsmtQual'].replace(['Ex','Gd'],'Above Average')\n",
    "housetest['BsmtQual']=housetest['BsmtQual'].replace(['Fa','Po'],'Below Average')\n",
    "#print(housetest['BsmtQual'].value_counts())\n",
    "\n",
    "# Foundation: One of the more standard options or other\n",
    "housetest['Foundation']=housetest['Foundation'].replace(['BrkTil','Slab','Stone','Wood'],'Other')\n",
    "#print(housetest['Foundation'].value_counts())\n",
    "group = housetest.columns.to_series().groupby(housetest.dtypes).groups # grouping columns by type\n",
    "groups={k.name: v for k, v in group.items()} #  creating as dictionary\n",
    "\n",
    "# Taking only the object type col names\n",
    "objects=housetest[groups['object'].values]\n",
    "for i in objects.columns:\n",
    "        #print('{} \\n' .format(objects[i]))\n",
    "        print(objects[i].value_counts())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode some categorical features as ordered numbers when there is information in the order\n",
    "housetest = housetest.replace({\"BsmtCond\" : {\"No\" : 0, \"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                        \"Fence\":{\"GdPrv\":2,\"GdWo\":2,\"MnPrv\":1,\"MnWw\":1,\"No\":0},\n",
    "                        \"LotShape\":{\"IRReg\":0,\"Reg\":1},\n",
    "                        \"CentralAir\":{\"N\":0,\"Y\":1},\n",
    "                        \"LandContour\":{\"NotFlat\":0,\"Lvl\":1},\n",
    "                        \"PavedDrive\":{\"N\":0,\"Y\":1,\"P\":1},\n",
    "                       \"BsmtQual\" : {\"No\" : 0, \"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"ExterCond\" : {\"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"ExterQual\" : {\"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"BsmtFinType1\":{\"No\":0,\"Unf\":1,\"Below Average\":1,\"Average\":2,\"GLQ\":3},\n",
    "                        \"BsmtFinType2\":{\"No\":0,\"Unf\":1,\"Below Average\":1,\"Average\":2,\"GLQ\":3},\n",
    "                       \"Functional\" : {\"Maj\" : 1, \"Mod\" : 2, \"Min\" : 3, \"Typ\" : 4},\n",
    "                       \"GarageCond\" : {\"No\" : 0, \"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"GarageQual\" : {\"No\" : 0, \"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"HeatingQC\" : {\"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"KitchenQual\" : {\"Below Average\" : 1, \"TA\" : 2, \"Above Average\":3},\n",
    "                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3}}\n",
    "                     )\n",
    "\n",
    "# Create new features\n",
    "# 1* Simplifications of existing features\n",
    "housetest[\"OverallQual\"] = housetest.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                                                       4 : 2, 5 : 2, 6 : 2, # average\n",
    "                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                                                      })\n",
    "housetest[\"OverallCond\"] = housetest.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                                                       4 : 2, 5 : 2, 6 : 2, # average\n",
    "                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                                                      })\n",
    "\n",
    "\n",
    "# Combining variables\n",
    "housetest['BsmtFinSF']=housetest['BsmtFinSF1']+housetest['BsmtFinSF2']\n",
    "housetest['PorchSF']=housetest['OpenPorchSF']+housetest['EnclosedPorch']+housetest['3SsnPorch']+housetest['ScreenPorch']\n",
    "\n",
    "\n",
    "group = housetest.columns.to_series().groupby(housetest.dtypes).groups # grouping columns by type\n",
    "groups={k.name: v for k, v in group.items()} #  creating as dictionary\n",
    "\n",
    "# Taking only the object type col names\n",
    "objects=housetest[groups['object'].values]\n",
    "for i in objects.columns:\n",
    "        #print('{} \\n' .format(objects[i]))\n",
    "        print(objects[i].value_counts())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing pool area / pool quality from data set and replacing with \"has pool\"\n",
    "housetest['hasPool'] = np.where(housetest['PoolArea']>0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising\n",
    "Most statistical methods (the parametric methods) include the assumption that the sample is drawn from a population where the values have a Normal distribution. One of the first steps of statistical analysis of your data is therefore to check the distribution of the different variables.\n",
    "\n",
    "Upon completing the task of dealing with missing values and errors in the data, it was decided to move on to normalising our data.\n",
    "\n",
    "The Normal distribution is symmetrical, not very peaked or very flat-topped, and if we examine the charts below we can see that our data is often skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Printing plots for int 64 and float64\n",
    "# #quantvar = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "#             'LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd',\n",
    "#             'Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea'\n",
    "#            ,'MiscVal','SalePrice']\n",
    "quantvar = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "            'LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','PorchSF','PoolArea'\n",
    "           ,'MiscVal']\n",
    "cont_plot=housetest[quantvar]\n",
    "for i in range(len(cont_plot.columns)):\n",
    "        plt.hist(cont_plot.iloc[:,i].dropna(),bins=30)\n",
    "        plt.title('%s' % cont_plot.columns[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the charts, we note several points of interest. We have several variables that skewed to the right. There do not appear to be any left skewed. This is more than likely caused by the presence of smaller outliers that were missed by our earlier scatter plot. \n",
    "\n",
    "For dealing with skew, the following transformations perform well:\n",
    "\n",
    "* The log transformation (sometimes computed log(x+A) where A is some constant. This is done to deal with negative or 0 values.\n",
    "* The Square Root function\n",
    "* Converting to a Fraction, i.e. 1/x\n",
    "* The Powers transformation\n",
    "\n",
    "We can also use some combination thereof. For our base model, it was decided to keep things simple. As we try to improve our models, we will try alternate methods.\n",
    "\n",
    "For right skewed data, the log transformation works well, and this was the selected transformation for our model for the severly right skewed data listed above. It is suspected that if the outliers were dealt with, the data would become more normally distributed. This was the decided approach with a view of returning to this as we seek to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_transform(feature):\n",
    "    housetest[feature] = np.log1p(housetest[feature].values) # does a log transform on x+1\n",
    "\n",
    "#log transforming variables\n",
    "log_transform('GrLivArea')\n",
    "log_transform('PorchSF')\n",
    "log_transform('1stFlrSF')\n",
    "log_transform('2ndFlrSF')\n",
    "log_transform('BsmtUnfSF')\n",
    "log_transform('BsmtFinSF')\n",
    "log_transform('TotalBsmtSF')\n",
    "log_transform('LotArea')\n",
    "log_transform('LotFrontage')\n",
    "log_transform('KitchenAbvGr')\n",
    "log_transform('GarageArea')\n",
    "log_transform('MasVnrArea')\n",
    "log_transform('WoodDeckSF')\n",
    "log_transform('PorchSF')\n",
    "\n",
    "quantvar = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "            'LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','PorchSF','PoolArea'\n",
    "           ,'MiscVal']\n",
    "cont_plot=housetest[quantvar]\n",
    "for i in range(len(cont_plot.columns)):\n",
    "        plt.hist(cont_plot.iloc[:,i].dropna(),bins=30)\n",
    "        plt.title('%s' % cont_plot.columns[i])\n",
    "        plt.show()\n",
    "# f = pd.melt(housetrain, value_vars=quantitative)\n",
    "# g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False)\n",
    "# g = g.map(sns.distplot, \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, using a log transformation we have normalised our data (excluding the zero values representing missing) and have tidied up the outliers.\n",
    "\n",
    "# Standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "def standard(data,method):\n",
    "    \"\"\"Standarising data using various methods.\n",
    "    \n",
    "    Method 1 is MinMax scaling \n",
    "    Method 2 is decimal\n",
    "    Method 3 is Z score\n",
    "    Version Control:\n",
    "    Initial coding\n",
    "    ------------------------------------------\n",
    "    Date 4-Feb-18, Author: Conor Feeney, Desc: Initial Coding\n",
    "    \"\"\"\n",
    "    if method == 1:\n",
    "        X_std = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))\n",
    "        data = X_std * (1 - 0) + 0\n",
    "        return data\n",
    "    elif method==2:\n",
    "        data = (data)/(10**len(str(int(max(data)))))\n",
    "        return data\n",
    "    elif method ==3:\n",
    "        data = (data - data.mean(axis=0))/data.std(axis=0)\n",
    "        data=st.norm.cdf(data)\n",
    "        return data\n",
    "    elif method==4:\n",
    "        return data\n",
    "    \n",
    "for i in range(len(housetest.columns)):     \n",
    "    if housetest.iloc[:,i].dtype !=object:   \n",
    "        housetest.iloc[:,i]=standard(housetest.iloc[:,i],3)\n",
    "housetest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Training model on the Test set\n",
    "Now that we have applied all recoding and transformations on the test set, we now apply that training model on the test set. Below we make the last edits to the data before we use the lasso model seen earlier to predict sale prices on the houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Testset=pd.DataFrame.copy(housetest)\n",
    "\n",
    "# dropping unneeded variables\n",
    "Testset=Testset.drop('Utilities',axis=1)\n",
    "Testset=Testset.drop('PoolQC',axis=1)\n",
    "Testset=Testset.drop('PoolArea',axis=1)\n",
    "\n",
    "# creating dummy variables for categorical variables\n",
    "group = Testset.columns.to_series().groupby(Testset.dtypes).groups # grouping columns by type\n",
    "groups={k.name: v for k, v in group.items()} #  creating as dictionary\n",
    "\n",
    "ID=pd.DataFrame.copy(Testset['Id'])\n",
    "# creating dummy variables for categorical variables\n",
    "dummies = pd.get_dummies(Testset[groups['object'].values])\n",
    "\n",
    "Testset = Testset.join(dummies)\n",
    "Testset=Testset.drop(Testset[groups['object'].values],axis=1)\n",
    "\n",
    "# Dropping variables due to recoding\n",
    "Testset=Testset.drop('GarageYrBlt',axis=1)\n",
    "Testset=Testset.drop('OpenPorchSF',axis=1)\n",
    "Testset=Testset.drop('EnclosedPorch',axis=1)\n",
    "Testset=Testset.drop('3SsnPorch',axis=1)\n",
    "Testset=Testset.drop('ScreenPorch',axis=1)\n",
    "Testset=Testset.drop('BsmtFinSF1',axis=1)\n",
    "Testset=Testset.drop('BsmtFinSF2',axis=1)\n",
    "\n",
    "#dropping variables due to no presence in training set / Id variable.\n",
    "Testset=Testset.drop('Id',axis=1)\n",
    "Testset=Testset.drop('MSSubClass_150',axis=1)\n",
    "\n",
    "Testset.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_las = clf.predict(Testset)\n",
    "print(y_test_las)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_test_las.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.count_nonzero(y_test_las))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
